{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd53a474",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a4b84-bb67-44e4-aa91-30f3d8bcc529",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute Demo: ENSO nonlinearity index with CMIP6 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff08e9",
   "metadata": {},
   "source": [
    "<img src=\"images/alpha_output.png\" width=550 alt=\"Alpha output\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd29c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6c01b-1e08-463d-90d5-b9e7be5a61ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this demo we combine multiple multiple tools described in previous cookbooks to subset, regrid and process CMIP6 data. We will be computing a measure of ENSO nonlinearity by computing the EOFs of the pacific sea surface temperature anomalies. This measure is particularly useful for characterizing models by their ability to represent different ENSO extremes (Karamperidou et al., 2017).\n",
    "\n",
    "The process we are going to follow in this demo is:\n",
    "\n",
    "1. Find the CMIP6 data we need using intake-esgf\n",
    "2. Subset the data and regrid it to a common grid using Rooki\n",
    "3. Load the datasets into xarray and perform the computations\n",
    "4. Plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3693d-4e01-4982-b1d0-dffcd2a13157",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Intro to Xarray](https://foundations.projectpythia.org/core/xarray/xarray-intro.html) | Necessary | How to use xarray to work with NetCDF data |\n",
    "| [Intro to Intake-ESGF](intro-search) | Necessary | How to configure a search and use output |\n",
    "| [Intro to Rooki](rooki) | Helpful | How to initialize and run rooki |\n",
    "| [Intro to EOFs](https://projectpythia.org/eofs-cookbook/notebooks/eof-intro.html) | Helpful | Understanding of EOFs |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **Time to learn**: 20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288086a4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2339b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import intake_esgf\n",
    "\n",
    "# Run this on the DKRZ node in Germany, using the ESGF1 index node at LLNL\n",
    "os.environ[\"ROOK_URL\"] = \"http://rook.dkrz.de/wps\"\n",
    "intake_esgf.conf.set(indices={\"anl-dev\": False,\n",
    "                               \"ornl-dev\": False,\n",
    "                               \"esgf-node.llnl.gov\": True})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as poly\n",
    "import xarray as xr\n",
    "import xeofs as xe\n",
    "from intake_esgf import ESGFCatalog\n",
    "from rooki import operators as ops\n",
    "from rooki import rooki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed87c2",
   "metadata": {},
   "source": [
    "## Retrieve subset of CMIP6 data\n",
    "\n",
    "The CMIP6 dataset is identified by a dataset-id. Using intake-esgf we can query the ESGF database for the variables and models we are interested in. For this demo we are interested in the tos (sea surface temperature) variable for the historical runs. Also, for sake of simplicity we will only query a subset of the models available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3b3c0-6aa0-465b-bc17-86ae2ce5f25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat = ESGFCatalog()\n",
    "cat.search(\n",
    "    experiment_id=[\"historical\"],\n",
    "    variable_id=[\"tos\"],\n",
    "    table_id=[\"Omon\"],\n",
    "    project=[\"CMIP6\"],\n",
    "    grid_label=[\"gn\"],\n",
    "    source_id=[\n",
    "        \"CAMS-CSM1-0\",\n",
    "        \"FGOALS-g3\",\n",
    "        \"CMCC-CM2-SR5\",\n",
    "        \"CNRM-CM6-1\",\n",
    "        \"CNRM-ESM2-1\",\n",
    "        \"CESM2\",\n",
    "    ],\n",
    ")\n",
    "cat.remove_ensembles()\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea426b",
   "metadata": {},
   "source": [
    "Once the catalog has been queried, we have to do some manipulation in pandas to keep only the dataset_id. This has to be done because the same data has multiple locations online, and these get appended at the end of the dataset_id. Rookie only accepts the dataset_id without the online location, so we get rid of it in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482b7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keep_ds_id(ds):\n",
    "    return ds[0].split(\"|\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46726e56-030d-4e54-a1a4-5e2f2ca11b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collections = cat.df.id.apply(keep_ds_id).to_list()\n",
    "collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d3941",
   "metadata": {},
   "source": [
    "We are left with a list of dataset_ids that Rookie can accept as input for the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a3b8b",
   "metadata": {},
   "source": [
    "## Subset and regrid the data\n",
    "\n",
    "We define a function that will do the subset and regridding for us for each of the dataset_ids we have. The function will take the dataset_id as input and then use Rookie functions to select 100 years of data for the tos variable in the Pacific Ocean region. We don't need high resolution data for this particular use, so 2.5 degree resolution is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8c66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pacific_ocean(dataset_id):\n",
    "    wf = ops.Regrid(\n",
    "        ops.Subset(\n",
    "            ops.Input(\"tos\", [dataset_id]),\n",
    "            time=\"1900-01-01/2000-01-31\",\n",
    "            area=\"100,-20,280,20\",\n",
    "        ),\n",
    "        method=\"nearest_s2d\",\n",
    "        grid=\"2pt5deg\",\n",
    "    )\n",
    "    resp = wf.orchestrate()\n",
    "    if resp.ok:\n",
    "        print(f\"{resp.size_in_mb=}\")\n",
    "        ds = resp.datasets()[0]\n",
    "    else:\n",
    "        ds = xr.Dataset()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbecbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sst_data = {dset: get_pacific_ocean(dset) for dset in collections}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46301d38",
   "metadata": {},
   "source": [
    "## ENSO nonlinearity measure: `alpha` value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b135d",
   "metadata": {},
   "source": [
    "This part of the demo is computation heavy. You can refer to Takahashi et al. (2011) and Karamperidou et al. (2017) for more details on the usefulness and computation of the `alpha` parameter.\n",
    "\n",
    "The `alpha` parameter is computed by doing a quadratic fit to the first two EOFs for the DJF season of the SST anomalies in the Pacific region. We are looking to obtain two EOFs modes that represent the Eastern and central pacific SST patterns, which is why we include a correction factor to account for the fact the sometimes the EOFs come with the opposite sign.\n",
    "\n",
    "The higher the value of `alpha`, the more nonlinear (or extreme) ENSO events can be represented by the model. Likewise, a model with lower `alpha` values will have a harder time representing extreme ENSO events, making it not suitable for climate studies of ENSO in a warming climate (Cai et al., 2018, 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99631cca",
   "metadata": {},
   "source": [
    "We are looking to obtain data that can reproduce a figure similar to the one below (taken from Karamperiou et al., 2017):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4266bc6",
   "metadata": {},
   "source": [
    "<img src=\"images/alpha_example.png\" alt=\"Alpha parameter\" style=\"width: 600px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2e06a",
   "metadata": {},
   "source": [
    "Each of the \"wings\" of this boomerang-shaped distribution represents a different ENSO extreme, with the left (right) wing representing the extreme central (eastern) pacific El Niño events. More details on Takahashi et al. (2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43be532-c565-45e7-84d8-21be6e4e351e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_alpha(pc1, pc2):\n",
    "    coefs = poly.polyfit(pc1, pc2, deg=2)\n",
    "    xfit = np.arange(pc1.min(), pc1.max() + 0.1, 0.1)\n",
    "    fit = poly.polyval(xfit, coefs)\n",
    "    return coefs[-1], xfit, fit\n",
    "\n",
    "\n",
    "def correction_factor(model):\n",
    "    _eofs = model.components()\n",
    "    _subset = dict(lat=slice(-5, 5), lon=slice(140, 180))\n",
    "    corr_factor = np.zeros(2)\n",
    "    corr_factor[0] = 1 if _eofs.sel(mode=1, **_subset).mean() > 0 else -1\n",
    "    corr_factor[1] = 1 if _eofs.sel(mode=2, **_subset).mean() > 0 else -1\n",
    "    return xr.DataArray(corr_factor, coords=[(\"mode\", [1, 2])])\n",
    "\n",
    "\n",
    "def compute_index(ds):\n",
    "    tos = ds.tos.sel(lat=slice(-20, 20), lon=slice(100, 280))\n",
    "    tos_anom = tos.groupby(\"time.month\").apply(lambda x: x - x.mean(\"time\"))\n",
    "\n",
    "    # Compute Eofs\n",
    "    model = xe.models.EOF(n_modes=2, use_coslat=True)\n",
    "    model.fit(tos_anom, dim=\"time\")\n",
    "    corr_factor = correction_factor(model)\n",
    "    # eofs = s_model.components()\n",
    "    scale_factor = model.singular_values() / np.sqrt(model.explained_variance())\n",
    "    pcs = (\n",
    "        model.scores().convert_calendar(\"standard\", align_on=\"date\")\n",
    "        * scale_factor\n",
    "        * corr_factor\n",
    "    )\n",
    "\n",
    "    pc1 = pcs.sel(mode=1)\n",
    "    pc1 = pc1.sel(time=pc1.time.dt.month.isin([12, 1, 2]))\n",
    "    pc1 = pc1.resample(time=\"QS-DEC\").mean().dropna(\"time\")\n",
    "\n",
    "    pc2 = pcs.sel(mode=2)\n",
    "    pc2 = pc2.sel(time=pc2.time.dt.month.isin([12, 1, 2]))\n",
    "    pc2 = pc2.resample(time=\"QS-DEC\").mean().dropna(\"time\")\n",
    "\n",
    "    alpha, xfit, fit = compute_alpha(pc1, pc2)\n",
    "\n",
    "    return pc1, pc2, alpha, xfit, fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334677a",
   "metadata": {},
   "source": [
    "Now we can compute the `alpha` parameter for each of the models we have selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ee71c-01ad-4df5-a4af-d3f7f28c622a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha_fits = {}\n",
    "for key, item in sst_data.items():\n",
    "    if len(item.variables) == 0:\n",
    "        continue\n",
    "    alpha_fits[key] = compute_index(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8714f85",
   "metadata": {},
   "source": [
    "## Plot the results\n",
    "\n",
    "Finally, we can plot the results of the `alpha` parameter for each of the models we have selected. This will give us an idea of how well the models represent different ENSO extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b327ec5-f261-4ae8-9ee8-19fff28b62dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(8, 12))\n",
    "axs = axs.ravel()\n",
    "for num, (ds, (pc1, pc2, alpha, xfit, fit)) in enumerate(alpha_fits.items()):\n",
    "    ax = axs[num]\n",
    "    ax.axhline(0, color=\"k\", linestyle=\"--\", alpha=0.2)\n",
    "    ax.axvline(0, color=\"k\", linestyle=\"--\", alpha=0.2)\n",
    "\n",
    "    # draw a line 45 degrees\n",
    "    x = np.linspace(-6, 6, 100)\n",
    "    y = x\n",
    "    ax.plot(x, y, color=\"k\", alpha=0.5, lw=1)\n",
    "    ax.plot(-x, y, color=\"k\", alpha=0.5, lw=1)\n",
    "\n",
    "    ax.scatter(\n",
    "        pc1,\n",
    "        pc2,\n",
    "        s=8,\n",
    "        marker=\"o\",\n",
    "        c=\"w\",\n",
    "        edgecolors=\"k\",\n",
    "        linewidths=0.5,\n",
    "    )\n",
    "\n",
    "    ax.plot(xfit, fit, c=\"r\", label=f\"$\\\\alpha=${alpha:.2f}\")\n",
    "\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "\n",
    "    ax.set_title(ds.split(\".\")[3])\n",
    "\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    ax.legend()\n",
    "fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67612b",
   "metadata": {},
   "source": [
    "From this example, we can see that from the subset of models we have selected, the `alpha` parameter is higher for CMCC-CM2-SR5 compared to the other models as the \"boomerang\" shape is better represented in this model. This indicates that this model is better at representing extreme ENSO events compared to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc1404-0030-4e7c-98bb-498c354301d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Summary\n",
    "In this notebook, we used intake-esgf with Rooki Python client to retrieve a subset of a CMIP6 dataset. The subset and regrid operations are executed remotely on a Rook subsetting service (using OGC API and xarray/clisops). The dataset is analyzed using xeofs to extract a measurement used in ENSO research. We also showed that remote operators can be chained to be executed in a single workflow operation.\n",
    "\n",
    "## Resources\n",
    "- [Roocs on GitHub](https://github.com/roocs)\n",
    "- [Copernicus Climate Data Store](https://cds.climate.copernicus.eu/)\n",
    "- [STAC](https://stacspec.org/en)\n",
    "\n",
    "## References\n",
    "- Cai, W., Santoso, A., Collins, M., Dewitte, B., Karamperidou, C., Kug, J.-S., Lengaigne, M., McPhaden, M. J., Stuecker, M. F., Taschetto, A. S., Timmermann, A., Wu, L., Yeh, S.-W., Wang, G., Ng, B., Jia, F., Yang, Y., Ying, J., Zheng, X.-T., … Zhong, W. (2021). Changing El Niño–Southern Oscillation in a warming climate. Nature Reviews Earth & Environment, 2(9), 628–644. https://doi.org/10.1038/s43017-021-00199-z\n",
    "- Cai, W., Wang, G., Dewitte, B., Wu, L., Santoso, A., Takahashi, K., Yang, Y., Carréric, A., & McPhaden, M. J. (2018). Increased variability of eastern Pacific El Niño under greenhouse warming. Nature, 564(7735), 201–206. https://doi.org/10.1038/s41586-018-0776-9\n",
    "- Karamperidou, C., Jin, F.-F., & Conroy, J. L. (2017). The importance of ENSO nonlinearities in tropical pacific response to external forcing. Climate Dynamics, 49(7), 2695–2704. https://doi.org/10.1007/s00382-016-3475-y\n",
    "- Takahashi, K., Montecinos, A., Goubanova, K., & Dewitte, B. (2011). ENSO regimes: Reinterpreting the canonical and Modoki El Niño. Geophysical Research Letters, 38(10). https://doi.org/10.1029/2011GL047364\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92000c2-4af7-407f-ac39-69988b083cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
